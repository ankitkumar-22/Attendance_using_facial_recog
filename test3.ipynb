{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importing the libraries "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c39623b8d8479d40"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-02T08:29:43.781147700Z",
     "start_time": "2024-10-02T08:29:29.936294700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Jet Brains\\DataSpell\\Attendance using facial rec\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "from retinaface import RetinaFace\n",
    "from deepface import DeepFace\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import datetime as datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import faiss\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "# Paths\n",
    "DATABASE_DIR = 'path_to_database_images'\n",
    "EMBEDDINGS_FILE = 'embeddings.pkl'\n",
    "ATTENDANCE_FILE = 'attendance_log.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T08:29:44.149714900Z",
     "start_time": "2024-10-02T08:29:43.782205Z"
    }
   },
   "id": "7e7a877d553ca529",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings loaded from embeddings.pkl\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "DATABASE_DIR = 'students'\n",
    "# Check if embeddings.pkl exists\n",
    "if os.path.exists(EMBEDDINGS_FILE):\n",
    "    # Load existing embeddings and labels\n",
    "    with open(EMBEDDINGS_FILE, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    embeddings = data['embeddings']\n",
    "    labels = data['labels']\n",
    "    print(\"Embeddings loaded from embeddings.pkl\")\n",
    "else: \n",
    "    for filename in os.listdir(DATABASE_DIR):\n",
    "        if filename.lower().endswith(('.png','.jpg',',jpeg')):\n",
    "            label = os.path.splitext(filename)[0] # to extract the name of the filename\n",
    "            img_path = os.path.join(DATABASE_DIR,filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            #Detect the faces \n",
    "            faces = RetinaFace.detect_faces(img)\n",
    "            if faces :\n",
    "                face = faces[next(iter(faces))]\n",
    "                x1,y1,x2,y2 = face['facial_area']\n",
    "                face_img = img[y1:y2, x1:x2]\n",
    "                \n",
    "                #Extract the face embeddings from the image \n",
    "                embedding_original = DeepFace.represent(face_img, model_name='ArcFace', detector_backend=\"retinaface\",enforce_detection= False,align = True)\n",
    "                embedding_dict = embedding_original[0]\n",
    "                embedding = embedding_dict[\"embedding\"]\n",
    "    \n",
    "                # Convert embedding to float32 and ensure it's a 1D array\n",
    "                embedding = np.array(embedding).astype('float32').flatten()\n",
    "    \n",
    "                embeddings.append(embedding)\n",
    "                label = np.array(label)\n",
    "                labels.append(label)\n",
    "                print(f\"{label} has been registered\")\n",
    "            else:\n",
    "                print(f'No face detected in the {filename}')        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T08:29:44.160145600Z",
     "start_time": "2024-10-02T08:29:44.154047400Z"
    }
   },
   "id": "187c04f0c72cf587",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings computed and stored in embeddings.pkl.\n"
     ]
    }
   ],
   "source": [
    "with open(EMBEDDINGS_FILE, 'wb') as f:\n",
    "    pickle.dump({'embeddings': embeddings, 'labels': labels}, f)\n",
    "print(\"Embeddings computed and stored in embeddings.pkl.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T08:29:51.723744200Z",
     "start_time": "2024-10-02T08:29:51.707427100Z"
    }
   },
   "id": "637c84c8dea55126",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings computed and stored.\n"
     ]
    }
   ],
   "source": [
    "labels = np.array(labels)\n",
    "with open(EMBEDDINGS_FILE, 'wb') as f:\n",
    "    pickle.dump({'embeddings': embeddings, 'labels': labels}, f)\n",
    "print(\"Embeddings computed and stored.\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T08:29:52.364359600Z",
     "start_time": "2024-10-02T08:29:52.356099500Z"
    }
   },
   "id": "10ccaa8a412d82fd",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings indexed: 20\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings and labels\n",
    "with open('embeddings.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "database_embeddings = data['embeddings']  # Shape: (num_samples, embedding_dim)\n",
    "database_labels = data['labels']\n",
    "database_embeddings = np.vstack(database_embeddings)\n",
    "# Dimension of the embeddings (e.g., 512 for Facenet)\n",
    "dimension = database_embeddings.shape[1]\n",
    "\n",
    "# Initialize FAISS index (Flat index for exact search)\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(database_embeddings)\n",
    "\n",
    "print(f\"Total embeddings indexed: {index.ntotal}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T08:29:53.053949300Z",
     "start_time": "2024-10-02T08:29:52.998419700Z"
    }
   },
   "id": "546733fc044d4e26",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae42f019ad4fa0f6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.373809]]\n",
      "[[16]]\n",
      "['Sahil Burnawal']\n",
      "[[17.361929]]\n",
      "[[4]]\n",
      "['Aniket ']\n",
      "[[12.261819]]\n",
      "[[11]]\n",
      "['Harish Gownatham']\n",
      "[[15.32501]]\n",
      "[[5]]\n",
      "['Anish']\n",
      "[[11.620642]]\n",
      "[[10]]\n",
      "['Haider Rizvy']\n",
      "[[17.56643]]\n",
      "[[11]]\n",
      "['Harish Gownatham']\n",
      "[[15.540201]]\n",
      "[[7]]\n",
      "['Ayon Binayak Ghosh']\n",
      "[[18.341595]]\n",
      "[[13]]\n",
      "['Krishnendu Basak']\n",
      "[[16.411453]]\n",
      "[[8]]\n",
      "['Basharat']\n",
      "[[8.421034]]\n",
      "[[7]]\n",
      "['Ayon Binayak Ghosh']\n",
      "[[12.400356]]\n",
      "[[9]]\n",
      "['Divya Raj ']\n",
      "[[11.919133]]\n",
      "[[17]]\n",
      "['Shaurya']\n",
      "[[13.009735]]\n",
      "[[3]]\n",
      "['Aman']\n"
     ]
    }
   ],
   "source": [
    " classroom_image = cv2.imread('classroom3.jpg')\n",
    "faces = RetinaFace.detect_faces(img_path = \"classroom3.jpg\")\n",
    "threshold = 40\n",
    "for face_key in faces:\n",
    "    face = faces[face_key]\n",
    "    x1,y1,x2,y2 = face['facial_area']\n",
    "    individual_image = classroom_image[y1:y2, x1:x2]\n",
    "    individual_embedding = DeepFace.represent(img_path = individual_image , model_name='ArcFace', detector_backend=\"retinaface\",enforce_detection= False,align = True)[0]\n",
    "    individual_embedding = individual_embedding['embedding']\n",
    "    individual_embedding = np.array(individual_embedding).astype('float32').reshape(1,-1)\n",
    "    distance , indices = index.search(individual_embedding, k=1)\n",
    "    print(distance)\n",
    "    print(indices)\n",
    "    print(database_labels[indices[0]])\n",
    "    cv2.rectangle(classroom_image,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "    cv2.putText(classroom_image,str(database_labels[indices[0]]),(x1-10,y1-10),3,1.5,(255,0,0),1,cv2.LINE_AA)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T08:32:12.237386Z",
     "start_time": "2024-10-02T08:29:54.729973900Z"
    }
   },
   "id": "b9f2bf7977530a91",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"output.jpg\", classroom_image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T08:32:12.523095500Z",
     "start_time": "2024-10-02T08:32:12.236306400Z"
    }
   },
   "id": "dae6c7b7ae6a5b60",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.8744]]\n",
      "[[4]]\n",
      "['Shreyansh Jain']\n",
      "[[12.715242]]\n",
      "[[1]]\n",
      "['Ankit']\n",
      "[[59.676903]]\n",
      "[[2]]\n",
      "['Harsh Murmu']\n"
     ]
    }
   ],
   "source": [
    " classroom_image = cv2.imread('classroom2.jpg')\n",
    "faces = RetinaFace.detect_faces(img_path = \"classroom2.jpg\")\n",
    "threshold = 40\n",
    "for face_key in faces:\n",
    "    face = faces[face_key]\n",
    "    x1,y1,x2,y2 = face['facial_area']\n",
    "    individual_image = classroom_image[y1:y2, x1:x2]\n",
    "    individual_embedding = DeepFace.represent(img_path = individual_image , model_name='ArcFace', detector_backend=\"retinaface\",enforce_detection= False,align = True)[0]\n",
    "    individual_embedding = individual_embedding['embedding']\n",
    "    individual_embedding = np.array(individual_embedding).astype('float32').reshape(1,-1)\n",
    "    distance , indices = index.search(individual_embedding, k=1)\n",
    "    print(distance)\n",
    "    print(indices)\n",
    "    print(database_labels[indices[0]])\n",
    "    cv2.rectangle(classroom_image,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "    cv2.putText(classroom_image,str(database_labels[indices[0]]),(x1-10,y1-10),3,1.5,(255,0,0),1,cv2.LINE_AA)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T11:55:40.286630400Z",
     "start_time": "2024-10-01T11:55:09.403032Z"
    }
   },
   "id": "a56f334f5b692948",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cv2.imwrite(\"Output2.jpg\",classroom_image)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9dbc14e784c628d7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
